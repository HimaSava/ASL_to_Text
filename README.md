# ASL_to_Text

This project converts live image inputs from a web cam to text by identifying the American Sign Language if any in the image. The code is completely done in python and using the OpenCv library for the image capturing and processing features.

As this was my summer project and I was just learning OpenCV for the first time the output of the system is not very accurate and with only brute force algorithm running to identify the signs it is also not very accurate.

### Scope for Improvement:

1. Using better skin recognition algorithms than just a simple filter to identify the hand better. This will also get rid of the backgorund noise and help tremendously in the identification process.
2. Adding a better algorithm or ideally an machine learning model for the recognition of the signs. At the present stage it can only identify few of the signs and that too with not much acuracy. A well trained model will make the project rather simple and way more usefull.

### Implementations:

1. A simple ASL to text converter for the audibly chanlenged people to use.
2. A phone call system that speaks the signs in the phone so that the challenged person can have a normal phone conversation.
3. An intermediate product to connect audibly challenged people to conect to voice activated devices like home automation systems, and much more...


